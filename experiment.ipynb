{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "import doc2vec\n",
    "import scipy.spatial.distance\n",
    "\n",
    "import rank_metrics\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # cancel optimization complaints by tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_data_folder = 'aminder_org_v1'\n",
    "rel_labels_fname = 'relevance_labels_' + raw_data_folder + '.p'\n",
    "doc2vec_model_folder = 'd2v_model'\n",
    "\n",
    "distance_measure = 'cosine'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing relevance labels using bm25... (this takes a while, but should only be done once..)\n",
      "111000\n",
      "Computing BM25...\n",
      "Done computing bm25, compute average IDF...\n",
      "Done computing average IDF.\n",
      "Computing relative scores...\n",
      "0 / 111000\n",
      "1000 / 111000\n",
      "2000 / 111000\n",
      "3000 / 111000\n",
      "4000 / 111000\n",
      "5000 / 111000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-e1990fc21794>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mprepare_relevance_labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mprepare_relevance_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_relevance_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_fname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrel_labels_fname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfolder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraw_data_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrel_labels_fname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Studie/Msc_AI/Thesis/regulatory tracker/doc2vec_pipeline/prepare_relevance_labels.py\u001b[0m in \u001b[0;36mprepare_relevance_labels\u001b[0;34m(output_fname, folder)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mlen_tokenized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenized\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenized\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mtemp_bm25_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbm25\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage_idf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0msorted_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_bm25_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtemp_bm25_scores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mbm25_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_bm25_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/regulatory_tracker/lib/python3.6/site-packages/gensim/summarization/bm25.py\u001b[0m in \u001b[0;36mget_scores\u001b[0;34m(self, document, average_idf)\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m             \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocument\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage_idf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m             \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/regulatory_tracker/lib/python3.6/site-packages/gensim/summarization/bm25.py\u001b[0m in \u001b[0;36mget_score\u001b[0;34m(self, document, index, average_idf)\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdocument\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0midf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mEPSILON\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0maverage_idf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Get relevance labels\n",
    "\"\"\"\n",
    "\n",
    "if not os.path.isfile(rel_labels_fname):\n",
    "    print('Computing relevance labels using bm25... (this takes a while, but should only be done once..)')\n",
    "    import prepare_relevance_labels\n",
    "\n",
    "    prepare_relevance_labels.prepare_relevance_labels(output_fname=rel_labels_fname, folder=raw_data_folder)\n",
    "\n",
    "with open(rel_labels_fname, 'rb') as f:\n",
    "    source_dict, docs, doc_names, tokenized, bm25_scores, sorted_bm25_indices = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Train paragraph vectors\n",
    "\"\"\"\n",
    "\n",
    "# Always train, because restoring does not work\n",
    "if not False:  # os.path.exists(doc2vec_model_folder):\n",
    "    print('Initializing and training paragraph vectors')\n",
    "    d2v = doc2vec.Doc2Vec(batch_size=128,\n",
    "                          window_size=8,\n",
    "                          concat=True,\n",
    "                          architecture='pvdm',\n",
    "                          embedding_size_w=300,  # word embedding size\n",
    "                          embedding_size_d=300,  # document embeding size\n",
    "                          vocabulary_size=50000,\n",
    "                          document_size=len(docs),\n",
    "                          loss_type='sampled_softmax_loss',\n",
    "                          n_neg_samples=64,\n",
    "                          optimize='Adagrad',\n",
    "                          learning_rate=1.0,\n",
    "                          n_steps=100001  # 100001\n",
    "                          )\n",
    "\n",
    "    d2v.fit(tokenized)\n",
    "    latest_checkpoint = d2v.save(doc2vec_model_folder)\n",
    "else:\n",
    "    d2v = doc2vec.Doc2Vec.restore(doc2vec_model_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2v = doc2vec.Doc2Vec.restore(doc2vec_model_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Evaluate\n",
    "\"\"\"\n",
    "distances = scipy.spatial.distance.squareform(scipy.spatial.distance.pdist(d2v.doc_embeddings, metric=distance_measure))\n",
    "\n",
    "results = []\n",
    "hits = []\n",
    "sorted_d2v_distance_indices = []\n",
    "for doc_index, distance in enumerate(distances):\n",
    "    sorted_distance_indices = sorted(range(len(distance)), key=lambda x: distance[x], reverse=False)\n",
    "    relevance_set = set(sorted_bm25_indices[doc_index][:10])\n",
    "    hit = np.array([ix in relevance_set for ix in sorted_distance_indices[:10]], dtype=int)\n",
    "    average_precision = rank_metrics.average_precision(hit)\n",
    "    ndcg_at_10 = rank_metrics.ndcg_at_k(hit, 10)\n",
    "    sorted_d2v_distance_indices.append(sorted_distance_indices)    \n",
    "    hits.append(hit)\n",
    "    results.append({\n",
    "        'average_precision': average_precision,\n",
    "        'ndcg_at_10': ndcg_at_10,\n",
    "    })\n",
    "\n",
    "print(\"MAP: \", rank_metrics.mean_average_precision(hits))\n",
    "print(\"MRR: \", rank_metrics.mean_reciprocal_rank(hits))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NDIMS = 64\n",
    "\n",
    "MAP:  0.646\n",
    "MRR:  0.711\n",
    "\n",
    "NDIMS = 128\n",
    "\n",
    "MAP:  0.651\n",
    "MRR:  0.707"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(results)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_result_difference(ix, number_of_articles=2):\n",
    "    print(\"Source document:\")\n",
    "    print(docs[ix], '\\nMost similar (BM25) documents:\\n' + 50*'-')\n",
    "    for i in sorted_bm25_indices[ix][:number_of_articles]:\n",
    "        print(i)\n",
    "        print(docs[i][:300] + '...')\n",
    "        print(25*'-')\n",
    "    print('\\nClosest Doc2Vec documents:\\n' + 50*'-')\n",
    "    for i in sorted_d2v_distance_indices[ix][:number_of_articles]:\n",
    "        print(i)\n",
    "        print(docs[i][:300] + '....')\n",
    "        print(25*'-')\n",
    "print_result_difference(300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
