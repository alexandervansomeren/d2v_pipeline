{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc2vec-gensim_aminer_org_v1_50000_5_300_300_cosine_0_True\n",
      "random_aminer_org_v1_50000_5_300_300_cosine_0_True\n"
     ]
    }
   ],
   "source": [
    "exp_folders = glob.glob('experiments/*/')\n",
    "params = {}\n",
    "fold_results = []\n",
    "folds = []\n",
    "for exp_folder in exp_folders:\n",
    "    exp_name = exp_folder.split(os.sep)[1]\n",
    "    if not os.path.exists(os.path.join(exp_folder, 'params.p')):\n",
    "        continue\n",
    "#     print(exp_name)\n",
    "    with open(os.path.join(exp_folder, 'params.p'), 'rb') as params_file:\n",
    "        params[exp_name] = pickle.load(params_file)\n",
    "    fold_folders = glob.glob(os.path.join(exp_folder,'fold*'))\n",
    "#     print(fold_folders)\n",
    "    for fold_folder in fold_folders:\n",
    "        result_file = os.path.join(fold_folder, 'trec_results')\n",
    "        if not os.path.exists(result_file):\n",
    "            rel_file = os.path.join(fold_folder, 'trec_rel_file.tmp')\n",
    "            top_file = os.path.join(fold_folder, 'trec_top_file.tmp')\n",
    "            print('Processing', fold_folder)\n",
    "            print(' '.join(['trec_eval -m all_trec', rel_file, top_file, '>', result_file,'2>&1']))\n",
    "            subprocess.call(' '.join(['trec_eval -m all_trec', rel_file, top_file, '>', result_file,'2>&1']), shell=True)\n",
    "            print('Done')\n",
    "        with open(result_file, 'r') as f:\n",
    "            temp_result_df = pd.read_csv(f, header=None, delimiter=r\"\\s+\")\n",
    "            temp_result_df = temp_result_df.pivot(index=1, columns=0, values=2)\n",
    "            folds.append(fold_folder.split('_')[-1])\n",
    "            temp_result_df.index = temp_result_df[['runid']] + \"_fold_\" + fold_folder.split('_')[-1]\n",
    "            fold_results.append(temp_result_df.copy())\n",
    "\n",
    "params_df = pd.DataFrame()\n",
    "fold_results = pd.concat(fold_results, axis=0)\n",
    "fold_results.loc[:, fold_results.columns != 'runid'] = fold_results.loc[:, fold_results.columns != 'runid'].apply(pd.to_numeric)\n",
    "fold_results['fold'] = folds\n",
    "params_df = pd.DataFrame.from_dict(params)\n",
    "unique_names = set([name[:-7] for name in fold_results.index])\n",
    "results = []\n",
    "for unique_name in unique_names:\n",
    "    print(unique_name)\n",
    "    res = fold_results[fold_results.index.str.contains(unique_name)].mean()\n",
    "    res.name = unique_name\n",
    "    results.append(res)\n",
    "\n",
    "results = pd.concat([params_df.T,pd.DataFrame(results)], axis=1)\n",
    "del results['fold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algorithm</th>\n",
       "      <th>architecture</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>concat</th>\n",
       "      <th>data</th>\n",
       "      <th>dist_measure</th>\n",
       "      <th>document_size</th>\n",
       "      <th>emb_size_d</th>\n",
       "      <th>emb_size_w</th>\n",
       "      <th>embedding_size_d</th>\n",
       "      <th>...</th>\n",
       "      <th>relative_P_500</th>\n",
       "      <th>set_F</th>\n",
       "      <th>set_P</th>\n",
       "      <th>set_map</th>\n",
       "      <th>set_recall</th>\n",
       "      <th>set_relative_P</th>\n",
       "      <th>success_1</th>\n",
       "      <th>success_10</th>\n",
       "      <th>success_5</th>\n",
       "      <th>utility</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>doc2vec-gensim_aminer_org_v1_50000_5_300_300_cosine_0_True</th>\n",
       "      <td>doc2vec-gensim</td>\n",
       "      <td>doc2vec-gensim</td>\n",
       "      <td>128</td>\n",
       "      <td>True</td>\n",
       "      <td>aminer_org_v1</td>\n",
       "      <td>cosine</td>\n",
       "      <td>34104.8</td>\n",
       "      <td>300</td>\n",
       "      <td>300</td>\n",
       "      <td>300</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00240</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00240</td>\n",
       "      <td>0.00240</td>\n",
       "      <td>0.00008</td>\n",
       "      <td>0.00036</td>\n",
       "      <td>0.00022</td>\n",
       "      <td>-99.99222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random_aminer_org_v1_50000_5_300_300_cosine_0_True</th>\n",
       "      <td>NaN</td>\n",
       "      <td>random</td>\n",
       "      <td>128</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34104.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>300</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00226</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00226</td>\n",
       "      <td>0.00226</td>\n",
       "      <td>0.00008</td>\n",
       "      <td>0.00034</td>\n",
       "      <td>0.00022</td>\n",
       "      <td>-99.99188</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 115 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         algorithm  \\\n",
       "doc2vec-gensim_aminer_org_v1_50000_5_300_300_co...  doc2vec-gensim   \n",
       "random_aminer_org_v1_50000_5_300_300_cosine_0_True             NaN   \n",
       "\n",
       "                                                      architecture batch_size  \\\n",
       "doc2vec-gensim_aminer_org_v1_50000_5_300_300_co...  doc2vec-gensim        128   \n",
       "random_aminer_org_v1_50000_5_300_300_cosine_0_True          random        128   \n",
       "\n",
       "                                                   concat           data  \\\n",
       "doc2vec-gensim_aminer_org_v1_50000_5_300_300_co...   True  aminer_org_v1   \n",
       "random_aminer_org_v1_50000_5_300_300_cosine_0_True   True            NaN   \n",
       "\n",
       "                                                   dist_measure document_size  \\\n",
       "doc2vec-gensim_aminer_org_v1_50000_5_300_300_co...       cosine       34104.8   \n",
       "random_aminer_org_v1_50000_5_300_300_cosine_0_True          NaN       34104.8   \n",
       "\n",
       "                                                   emb_size_d emb_size_w  \\\n",
       "doc2vec-gensim_aminer_org_v1_50000_5_300_300_co...        300        300   \n",
       "random_aminer_org_v1_50000_5_300_300_cosine_0_True        NaN        NaN   \n",
       "\n",
       "                                                   embedding_size_d    ...     \\\n",
       "doc2vec-gensim_aminer_org_v1_50000_5_300_300_co...              300    ...      \n",
       "random_aminer_org_v1_50000_5_300_300_cosine_0_True              300    ...      \n",
       "\n",
       "                                                   relative_P_500   set_F  \\\n",
       "doc2vec-gensim_aminer_org_v1_50000_5_300_300_co...        0.00240  0.0001   \n",
       "random_aminer_org_v1_50000_5_300_300_cosine_0_True        0.00226  0.0001   \n",
       "\n",
       "                                                   set_P set_map set_recall  \\\n",
       "doc2vec-gensim_aminer_org_v1_50000_5_300_300_co...   0.0     0.0    0.00240   \n",
       "random_aminer_org_v1_50000_5_300_300_cosine_0_True   0.0     0.0    0.00226   \n",
       "\n",
       "                                                   set_relative_P success_1  \\\n",
       "doc2vec-gensim_aminer_org_v1_50000_5_300_300_co...        0.00240   0.00008   \n",
       "random_aminer_org_v1_50000_5_300_300_cosine_0_True        0.00226   0.00008   \n",
       "\n",
       "                                                   success_10 success_5  \\\n",
       "doc2vec-gensim_aminer_org_v1_50000_5_300_300_co...    0.00036   0.00022   \n",
       "random_aminer_org_v1_50000_5_300_300_cosine_0_True    0.00034   0.00022   \n",
       "\n",
       "                                                     utility  \n",
       "doc2vec-gensim_aminer_org_v1_50000_5_300_300_co... -99.99222  \n",
       "random_aminer_org_v1_50000_5_300_300_cosine_0_True -99.99188  \n",
       "\n",
       "[2 rows x 115 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc2vec-gensim_aminer_org_v1_50000_5_300_300_cosine_0_True\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "scope_exp_name = \"doc2vec-gensim_aminer_org_v1_50000_5_300_300_cosine_0_True\"\n",
    "for exp_folder in exp_folders:\n",
    "    exp_name = exp_folder.split(os.sep)[1]\n",
    "    if exp_name == scope_exp_name:\n",
    "        print(exp_name)\n",
    "        fold_folders = glob.glob(os.path.join(exp_folder,'fold*'))\n",
    "        for fold_folder in fold_folders:\n",
    "            gt_fname = os.path.join(fold_folder, 'trec_rel_file.tmp')\n",
    "            res_fname = os.path.join(fold_folder, 'trec_top_file.tmp')\n",
    "            gt_d = []\n",
    "            res_d = []\n",
    "            with open(gt_fname, 'r') as f:\n",
    "                gt_d.extend(f.readline().split(' ') for i in range(250))\n",
    "            with open(res_fname, 'r') as f:\n",
    "                res_d.extend(f.readline().split(' ') for i in range(250))\n",
    "            break\n",
    "        break\n",
    "gt = defaultdict(list)\n",
    "res = defaultdict(list)\n",
    "for line in gt_d:\n",
    "    gt[line[0]].append(line[2])\n",
    "for line in res_d:\n",
    "    res[line[0]].append(line[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'11631': [],\n",
       "             '146': ['352303',\n",
       "              '254284',\n",
       "              '4195',\n",
       "              '101108',\n",
       "              '601381',\n",
       "              '298272',\n",
       "              '611540',\n",
       "              '4208',\n",
       "              '354215',\n",
       "              '612499',\n",
       "              '2509',\n",
       "              '307483',\n",
       "              '105162',\n",
       "              '39751',\n",
       "              '4210',\n",
       "              '77531',\n",
       "              '438543',\n",
       "              '303837',\n",
       "              '376232',\n",
       "              '44703',\n",
       "              '330788',\n",
       "              '602316',\n",
       "              '315820',\n",
       "              '321920',\n",
       "              '81197',\n",
       "              '496025',\n",
       "              '178668',\n",
       "              '432459',\n",
       "              '332781',\n",
       "              '539940',\n",
       "              '323973',\n",
       "              '248262',\n",
       "              '389938',\n",
       "              '311114',\n",
       "              '98068',\n",
       "              '413106',\n",
       "              '486196',\n",
       "              '282521',\n",
       "              '134390',\n",
       "              '443540',\n",
       "              '331137',\n",
       "              '253208',\n",
       "              '443340',\n",
       "              '578877',\n",
       "              '346823',\n",
       "              '86887',\n",
       "              '584108',\n",
       "              '79548',\n",
       "              '69634',\n",
       "              '353131',\n",
       "              '141334',\n",
       "              '464397',\n",
       "              '471133',\n",
       "              '143789',\n",
       "              '547618',\n",
       "              '179712',\n",
       "              '288809',\n",
       "              '282895',\n",
       "              '501766',\n",
       "              '444132',\n",
       "              '62994',\n",
       "              '364140',\n",
       "              '136377',\n",
       "              '508676',\n",
       "              '239066',\n",
       "              '165325',\n",
       "              '426454',\n",
       "              '89662',\n",
       "              '325258',\n",
       "              '290561',\n",
       "              '431073',\n",
       "              '611970',\n",
       "              '425417',\n",
       "              '282908',\n",
       "              '65322',\n",
       "              '330303',\n",
       "              '72705',\n",
       "              '108674',\n",
       "              '82784',\n",
       "              '43157',\n",
       "              '270148',\n",
       "              '73466',\n",
       "              '313439',\n",
       "              '38935',\n",
       "              '68786',\n",
       "              '625073',\n",
       "              '432694',\n",
       "              '90422',\n",
       "              '81916',\n",
       "              '289810',\n",
       "              '619912',\n",
       "              '146403',\n",
       "              '293919',\n",
       "              '38692',\n",
       "              '139801',\n",
       "              '61248',\n",
       "              '499181',\n",
       "              '362118',\n",
       "              '74927',\n",
       "              '445848'],\n",
       "             '188': ['129969',\n",
       "              '511133',\n",
       "              '436083',\n",
       "              '246346',\n",
       "              '239508',\n",
       "              '156026',\n",
       "              '574382',\n",
       "              '326722',\n",
       "              '439642',\n",
       "              '616999',\n",
       "              '327482',\n",
       "              '464397',\n",
       "              '442344',\n",
       "              '486196',\n",
       "              '388435',\n",
       "              '326842',\n",
       "              '397553',\n",
       "              '58305',\n",
       "              '421673',\n",
       "              '567917',\n",
       "              '547618',\n",
       "              '334428',\n",
       "              '56273',\n",
       "              '508676',\n",
       "              '452349',\n",
       "              '240032',\n",
       "              '61407',\n",
       "              '29757',\n",
       "              '314566',\n",
       "              '282521',\n",
       "              '581594',\n",
       "              '301909',\n",
       "              '496827',\n",
       "              '101820',\n",
       "              '449619',\n",
       "              '182161',\n",
       "              '477399',\n",
       "              '584108',\n",
       "              '209729',\n",
       "              '311392',\n",
       "              '432516',\n",
       "              '45283',\n",
       "              '416682',\n",
       "              '362118',\n",
       "              '420615',\n",
       "              '554632',\n",
       "              '442783',\n",
       "              '596886',\n",
       "              '36608',\n",
       "              '622832'],\n",
       "             '225': [],\n",
       "             '249': [],\n",
       "             '53': ['68197',\n",
       "              '503641',\n",
       "              '434281',\n",
       "              '284492',\n",
       "              '458139',\n",
       "              '339278',\n",
       "              '17604',\n",
       "              '32478',\n",
       "              '205806',\n",
       "              '63566',\n",
       "              '43790',\n",
       "              '495383',\n",
       "              '285968',\n",
       "              '339450',\n",
       "              '469637',\n",
       "              '427547',\n",
       "              '313050',\n",
       "              '299937',\n",
       "              '239870',\n",
       "              '92162',\n",
       "              '298631',\n",
       "              '414802',\n",
       "              '439589',\n",
       "              '303861',\n",
       "              '302771',\n",
       "              '320014',\n",
       "              '421073',\n",
       "              '417222',\n",
       "              '51738',\n",
       "              '620676',\n",
       "              '300903',\n",
       "              '791',\n",
       "              '22522',\n",
       "              '468339',\n",
       "              '51117',\n",
       "              '49903',\n",
       "              '73786',\n",
       "              '437887',\n",
       "              '44968',\n",
       "              '426246',\n",
       "              '353290',\n",
       "              '554414',\n",
       "              '88168',\n",
       "              '591325',\n",
       "              '551269',\n",
       "              '21003',\n",
       "              '549882',\n",
       "              '431729',\n",
       "              '158859',\n",
       "              '442788',\n",
       "              '495754',\n",
       "              '165791',\n",
       "              '546810',\n",
       "              '444221',\n",
       "              '146707',\n",
       "              '424703',\n",
       "              '598021',\n",
       "              '176629',\n",
       "              '15556',\n",
       "              '114553',\n",
       "              '322764',\n",
       "              '324231',\n",
       "              '332788',\n",
       "              '253959',\n",
       "              '235671',\n",
       "              '440838',\n",
       "              '325260',\n",
       "              '618254',\n",
       "              '226761',\n",
       "              '235673',\n",
       "              '74515',\n",
       "              '345703',\n",
       "              '439176',\n",
       "              '239725',\n",
       "              '135247',\n",
       "              '325152',\n",
       "              '38929',\n",
       "              '252675',\n",
       "              '112209',\n",
       "              '94432',\n",
       "              '414585',\n",
       "              '108998',\n",
       "              '157202',\n",
       "              '552392',\n",
       "              '285535',\n",
       "              '86162',\n",
       "              '520409',\n",
       "              '529951',\n",
       "              '30291',\n",
       "              '295571',\n",
       "              '582748',\n",
       "              '429887',\n",
       "              '546279',\n",
       "              '313316',\n",
       "              '427956',\n",
       "              '38687',\n",
       "              '317114',\n",
       "              '73407',\n",
       "              '492927',\n",
       "              '348697']})"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Original ----\n",
      "146 Finite difference approximations of the second derivative in space appearing in, parabolic, incompletely parabolic systems of, and 2nd-order hyperbolic, partial differential equations are considered. If the solution is pointwise bounded, we prove that finite difference approximations of those classes of equations can be closed with two orders less accuracy at the boundary without reducing the global order of accuracy.This result is generalised to initial-boundary value problems with an mth-o\n",
      "-----    GT    ----\n",
      "-----  Found   ----\n",
      "> 352303 We present an efficient protocol for privacy-preserving evaluation of diagnostic programs, represented as binary decision trees or branching programs. The protocol applies a branching diagnostic program with classification labels in the leaves to the user's attribute vector. The user learns only the label assigned by the program to his vector; the diagnostic program itself remains secret. The program's owner does not learn anything. Our construction is significantly more efficient than th\n",
      "> 254284 The importance of Object-Oriented techniques is perhaps one of the most significant changes in programming over the last decade or more; in 1991, a team of three (Jacob Brickman, Michael J. Kent, and the author) began looking into what would be required to extend APL interpreters to provide native support for OO. At this writing, we have a great deal of agreement about overall architecture, some significant issues to resolve, an overall consensus that it is time to share these ideas, and \n",
      "> 4195 Feature selection is used for finding a feature subset that has the most discriminative information from the original feature set. In practice, since we do not know the classifier to be used after feature selection, it is desirable to find a feature subset that is universally effective for any classifier. Such a trial is called classifier-independent feature selection. In this study, we propose a novel classifier-independent feature selection method on the basis of the estimation of Bayes d\n",
      "> 101108 In this paper we are concerned with broadband wireless access via high altitude platform system, providing the Internet access and broadband multimedia services to passengers equipped with WLAN terminals connecting through a collective terminal mounted on the train. The main challenge in such scenario is the development of efficient and reliable radio interface for the broadband communication link in the mobile wireless access segment. We are focusing on performance analysis of the adapti\n",
      "> 601381 This paper deals with stochastic optimization of a discrete-event simulation model for the solution of a manufacturing system operation problem. Gradient estimates are obtained by the application of the infinitesimal perturbation analysis (IPA) technique. We begin with background material on stochastic approximation (SA) and the IPA technique, their potential value in finding optimal solutions to manufacturing system operation problems, and limitations concerning their applicability. Next\n"
     ]
    }
   ],
   "source": [
    "def raw_text(doc_name, limit=500):\n",
    "    with open('raw_data.tmp/aminer_org_v1/texts.txt', 'r') as f:\n",
    "        for line in f:\n",
    "            if line[:10].split(' ')[0] == doc_name:\n",
    "                if limit > 0:\n",
    "                    line = line[:limit]\n",
    "                return line\n",
    "doc_name = '146'\n",
    "print('----- Original ----')\n",
    "print(raw_text(doc_name))\n",
    "print('-----    GT    ----')\n",
    "for t in gt[doc_name]:\n",
    "    print('>', raw_text(t))\n",
    "print('-----  Found   ----')\n",
    "for t in res[doc_name][:5]:\n",
    "    print('>', raw_text(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'doc_names' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-bac25cc425f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdoc_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'doc_names' is not defined"
     ]
    }
   ],
   "source": [
    "doc_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algorithm</th>\n",
       "      <th>architecture</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>concat</th>\n",
       "      <th>data</th>\n",
       "      <th>dist_measure</th>\n",
       "      <th>document_size</th>\n",
       "      <th>emb_size_d</th>\n",
       "      <th>emb_size_w</th>\n",
       "      <th>embedding_size_d</th>\n",
       "      <th>...</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>loss_type</th>\n",
       "      <th>n_neg_samples</th>\n",
       "      <th>n_steps</th>\n",
       "      <th>optimize</th>\n",
       "      <th>remove_docs_without_links</th>\n",
       "      <th>sample</th>\n",
       "      <th>seed</th>\n",
       "      <th>vocabulary_size</th>\n",
       "      <th>window_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>doc2vec-gensim_aminer_org_v1_50000_5_300_300_cosine_0_True</th>\n",
       "      <td>doc2vec-gensim</td>\n",
       "      <td>doc2vec-gensim</td>\n",
       "      <td>128</td>\n",
       "      <td>True</td>\n",
       "      <td>aminer_org_v1</td>\n",
       "      <td>cosine</td>\n",
       "      <td>34104.8</td>\n",
       "      <td>300</td>\n",
       "      <td>300</td>\n",
       "      <td>300</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>sampled_softmax_loss</td>\n",
       "      <td>64</td>\n",
       "      <td>170524</td>\n",
       "      <td>Adagrad</td>\n",
       "      <td>True</td>\n",
       "      <td>50000</td>\n",
       "      <td>0</td>\n",
       "      <td>50000</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random_aminer_org_v1_50000_5_300_300_cosine_0_True</th>\n",
       "      <td>NaN</td>\n",
       "      <td>random</td>\n",
       "      <td>128</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34104.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>300</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>sampled_softmax_loss</td>\n",
       "      <td>64</td>\n",
       "      <td>170524</td>\n",
       "      <td>Adagrad</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50000</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         algorithm  \\\n",
       "doc2vec-gensim_aminer_org_v1_50000_5_300_300_co...  doc2vec-gensim   \n",
       "random_aminer_org_v1_50000_5_300_300_cosine_0_True             NaN   \n",
       "\n",
       "                                                      architecture batch_size  \\\n",
       "doc2vec-gensim_aminer_org_v1_50000_5_300_300_co...  doc2vec-gensim        128   \n",
       "random_aminer_org_v1_50000_5_300_300_cosine_0_True          random        128   \n",
       "\n",
       "                                                   concat           data  \\\n",
       "doc2vec-gensim_aminer_org_v1_50000_5_300_300_co...   True  aminer_org_v1   \n",
       "random_aminer_org_v1_50000_5_300_300_cosine_0_True   True            NaN   \n",
       "\n",
       "                                                   dist_measure document_size  \\\n",
       "doc2vec-gensim_aminer_org_v1_50000_5_300_300_co...       cosine       34104.8   \n",
       "random_aminer_org_v1_50000_5_300_300_cosine_0_True          NaN       34104.8   \n",
       "\n",
       "                                                   emb_size_d emb_size_w  \\\n",
       "doc2vec-gensim_aminer_org_v1_50000_5_300_300_co...        300        300   \n",
       "random_aminer_org_v1_50000_5_300_300_cosine_0_True        NaN        NaN   \n",
       "\n",
       "                                                   embedding_size_d  \\\n",
       "doc2vec-gensim_aminer_org_v1_50000_5_300_300_co...              300   \n",
       "random_aminer_org_v1_50000_5_300_300_cosine_0_True              300   \n",
       "\n",
       "                                                       ...     learning_rate  \\\n",
       "doc2vec-gensim_aminer_org_v1_50000_5_300_300_co...     ...                 1   \n",
       "random_aminer_org_v1_50000_5_300_300_cosine_0_True     ...                 1   \n",
       "\n",
       "                                                               loss_type  \\\n",
       "doc2vec-gensim_aminer_org_v1_50000_5_300_300_co...  sampled_softmax_loss   \n",
       "random_aminer_org_v1_50000_5_300_300_cosine_0_True  sampled_softmax_loss   \n",
       "\n",
       "                                                   n_neg_samples n_steps  \\\n",
       "doc2vec-gensim_aminer_org_v1_50000_5_300_300_co...            64  170524   \n",
       "random_aminer_org_v1_50000_5_300_300_cosine_0_True            64  170524   \n",
       "\n",
       "                                                   optimize  \\\n",
       "doc2vec-gensim_aminer_org_v1_50000_5_300_300_co...  Adagrad   \n",
       "random_aminer_org_v1_50000_5_300_300_cosine_0_True  Adagrad   \n",
       "\n",
       "                                                   remove_docs_without_links  \\\n",
       "doc2vec-gensim_aminer_org_v1_50000_5_300_300_co...                      True   \n",
       "random_aminer_org_v1_50000_5_300_300_cosine_0_True                       NaN   \n",
       "\n",
       "                                                   sample seed  \\\n",
       "doc2vec-gensim_aminer_org_v1_50000_5_300_300_co...  50000    0   \n",
       "random_aminer_org_v1_50000_5_300_300_cosine_0_True    NaN  NaN   \n",
       "\n",
       "                                                   vocabulary_size window_size  \n",
       "doc2vec-gensim_aminer_org_v1_50000_5_300_300_co...           50000           8  \n",
       "random_aminer_org_v1_50000_5_300_300_cosine_0_True           50000           8  \n",
       "\n",
       "[2 rows x 22 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>average_precision</th>\n",
       "      <th>ndcg_at_10</th>\n",
       "      <th>n_steps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pvdm_original_articles_1_300_300_cosine</th>\n",
       "      <td>0.203961</td>\n",
       "      <td>0.228228</td>\n",
       "      <td>1031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pvdm_original_articles_5_300_300_cosine</th>\n",
       "      <td>0.926748</td>\n",
       "      <td>0.932935</td>\n",
       "      <td>5155</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         average_precision  ndcg_at_10 n_steps\n",
       "pvdm_original_articles_1_300_300_cosine           0.203961    0.228228    1031\n",
       "pvdm_original_articles_5_300_300_cosine           0.926748    0.932935    5155"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_folders = glob.glob('experiments/*/')\n",
    "params = {}\n",
    "results = {}\n",
    "for exp_folder in exp_folders:\n",
    "    exp_name = exp_folder.split(os.sep)[1]\n",
    "    if not os.path.exists(os.path.join(exp_folder, 'params.p')):\n",
    "        continue\n",
    "    with open(os.path.join(exp_folder, 'params.p'), 'rb') as params_file:\n",
    "        params[exp_name] = pickle.load(params_file)\n",
    "    with open(os.path.join(exp_folder, 'results.p'), 'rb') as results_file:\n",
    "        results[exp_name] = pickle.load(results_file)\n",
    "\n",
    "result_df = pd.DataFrame()\n",
    "params_df = pd.DataFrame()\n",
    "for exp, result in results.items():\n",
    "    mean_result = pd.DataFrame.from_dict(result).mean()\n",
    "    mean_result.name=exp\n",
    "    result_df = result_df.append(mean_result)\n",
    "result_df = pd.concat([result_df, pd.DataFrame.from_dict(params).T], axis=1)\n",
    "result_df[['average_precision', 'ndcg_at_10', 'n_steps']].sort_values('n_steps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>average_precision</th>\n",
       "      <th>ndcg_at_10</th>\n",
       "      <th>algorithm</th>\n",
       "      <th>architecture</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>concat</th>\n",
       "      <th>data</th>\n",
       "      <th>dist_measure</th>\n",
       "      <th>document_size</th>\n",
       "      <th>emb_size_d</th>\n",
       "      <th>...</th>\n",
       "      <th>iterations</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>loss_type</th>\n",
       "      <th>n_neg_samples</th>\n",
       "      <th>n_steps</th>\n",
       "      <th>nsteps</th>\n",
       "      <th>optimize</th>\n",
       "      <th>prior_sample_size</th>\n",
       "      <th>vocabulary_size</th>\n",
       "      <th>window_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>doc2vec-gensim_aminer_org_v1_5_300_300_cosine</th>\n",
       "      <td>0.000702</td>\n",
       "      <td>0.001029</td>\n",
       "      <td>doc2vec-gensim</td>\n",
       "      <td>pvdm</td>\n",
       "      <td>128</td>\n",
       "      <td>True</td>\n",
       "      <td>aminer_org_v1</td>\n",
       "      <td>cosine</td>\n",
       "      <td>111000</td>\n",
       "      <td>300</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>sampled_softmax_loss</td>\n",
       "      <td>64</td>\n",
       "      <td>555000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adagrad</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50000</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doc2vec-gensim_original_articles_100001_300_300_cosine</th>\n",
       "      <td>0.677843</td>\n",
       "      <td>0.687516</td>\n",
       "      <td>doc2vec-gensim</td>\n",
       "      <td>pvdm</td>\n",
       "      <td>128</td>\n",
       "      <td>True</td>\n",
       "      <td>original_articles</td>\n",
       "      <td>cosine</td>\n",
       "      <td>1031</td>\n",
       "      <td>300</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>sampled_softmax_loss</td>\n",
       "      <td>64</td>\n",
       "      <td>100001</td>\n",
       "      <td>100001</td>\n",
       "      <td>Adagrad</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50000</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doc2vec-gensim_original_articles_5_100_100_cosine</th>\n",
       "      <td>0.675223</td>\n",
       "      <td>0.680724</td>\n",
       "      <td>doc2vec-gensim</td>\n",
       "      <td>pvdm</td>\n",
       "      <td>128</td>\n",
       "      <td>True</td>\n",
       "      <td>original_articles</td>\n",
       "      <td>cosine</td>\n",
       "      <td>1031</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>sampled_softmax_loss</td>\n",
       "      <td>64</td>\n",
       "      <td>5155</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adagrad</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50000</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doc2vec-gensim_original_articles_5_300_300_cosine</th>\n",
       "      <td>0.673040</td>\n",
       "      <td>0.682589</td>\n",
       "      <td>doc2vec-gensim</td>\n",
       "      <td>pvdm</td>\n",
       "      <td>128</td>\n",
       "      <td>True</td>\n",
       "      <td>original_articles</td>\n",
       "      <td>cosine</td>\n",
       "      <td>1031</td>\n",
       "      <td>300</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>sampled_softmax_loss</td>\n",
       "      <td>64</td>\n",
       "      <td>5155</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adagrad</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50000</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pvdm_original_articles_10000_300_300_cosine</th>\n",
       "      <td>0.649623</td>\n",
       "      <td>0.670708</td>\n",
       "      <td>pvdm</td>\n",
       "      <td>pvdm</td>\n",
       "      <td>128</td>\n",
       "      <td>True</td>\n",
       "      <td>original_articles</td>\n",
       "      <td>cosine</td>\n",
       "      <td>1031</td>\n",
       "      <td>300</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>sampled_softmax_loss</td>\n",
       "      <td>64</td>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "      <td>Adagrad</td>\n",
       "      <td>10</td>\n",
       "      <td>50000</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pvdm_original_articles_1000_300_300_cosine</th>\n",
       "      <td>0.674012</td>\n",
       "      <td>0.685618</td>\n",
       "      <td>pvdm</td>\n",
       "      <td>pvdm</td>\n",
       "      <td>128</td>\n",
       "      <td>True</td>\n",
       "      <td>original_articles</td>\n",
       "      <td>cosine</td>\n",
       "      <td>1031</td>\n",
       "      <td>300</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>sampled_softmax_loss</td>\n",
       "      <td>64</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>Adagrad</td>\n",
       "      <td>10</td>\n",
       "      <td>50000</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pvdm_original_articles_100_300_300_cosine</th>\n",
       "      <td>0.679642</td>\n",
       "      <td>0.689899</td>\n",
       "      <td>pvdm</td>\n",
       "      <td>pvdm</td>\n",
       "      <td>128</td>\n",
       "      <td>True</td>\n",
       "      <td>original_articles</td>\n",
       "      <td>cosine</td>\n",
       "      <td>1031</td>\n",
       "      <td>300</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>sampled_softmax_loss</td>\n",
       "      <td>64</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>Adagrad</td>\n",
       "      <td>10</td>\n",
       "      <td>50000</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pvdm_original_articles_50000_300_300_cosine</th>\n",
       "      <td>0.639258</td>\n",
       "      <td>0.665104</td>\n",
       "      <td>pvdm</td>\n",
       "      <td>pvdm</td>\n",
       "      <td>128</td>\n",
       "      <td>True</td>\n",
       "      <td>original_articles</td>\n",
       "      <td>cosine</td>\n",
       "      <td>1031</td>\n",
       "      <td>300</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>sampled_softmax_loss</td>\n",
       "      <td>64</td>\n",
       "      <td>50000</td>\n",
       "      <td>50000</td>\n",
       "      <td>Adagrad</td>\n",
       "      <td>10</td>\n",
       "      <td>50000</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    average_precision  \\\n",
       "doc2vec-gensim_aminer_org_v1_5_300_300_cosine                0.000702   \n",
       "doc2vec-gensim_original_articles_100001_300_300...           0.677843   \n",
       "doc2vec-gensim_original_articles_5_100_100_cosine            0.675223   \n",
       "doc2vec-gensim_original_articles_5_300_300_cosine            0.673040   \n",
       "pvdm_original_articles_10000_300_300_cosine                  0.649623   \n",
       "pvdm_original_articles_1000_300_300_cosine                   0.674012   \n",
       "pvdm_original_articles_100_300_300_cosine                    0.679642   \n",
       "pvdm_original_articles_50000_300_300_cosine                  0.639258   \n",
       "\n",
       "                                                    ndcg_at_10  \\\n",
       "doc2vec-gensim_aminer_org_v1_5_300_300_cosine         0.001029   \n",
       "doc2vec-gensim_original_articles_100001_300_300...    0.687516   \n",
       "doc2vec-gensim_original_articles_5_100_100_cosine     0.680724   \n",
       "doc2vec-gensim_original_articles_5_300_300_cosine     0.682589   \n",
       "pvdm_original_articles_10000_300_300_cosine           0.670708   \n",
       "pvdm_original_articles_1000_300_300_cosine            0.685618   \n",
       "pvdm_original_articles_100_300_300_cosine             0.689899   \n",
       "pvdm_original_articles_50000_300_300_cosine           0.665104   \n",
       "\n",
       "                                                         algorithm  \\\n",
       "doc2vec-gensim_aminer_org_v1_5_300_300_cosine       doc2vec-gensim   \n",
       "doc2vec-gensim_original_articles_100001_300_300...  doc2vec-gensim   \n",
       "doc2vec-gensim_original_articles_5_100_100_cosine   doc2vec-gensim   \n",
       "doc2vec-gensim_original_articles_5_300_300_cosine   doc2vec-gensim   \n",
       "pvdm_original_articles_10000_300_300_cosine                   pvdm   \n",
       "pvdm_original_articles_1000_300_300_cosine                    pvdm   \n",
       "pvdm_original_articles_100_300_300_cosine                     pvdm   \n",
       "pvdm_original_articles_50000_300_300_cosine                   pvdm   \n",
       "\n",
       "                                                   architecture batch_size  \\\n",
       "doc2vec-gensim_aminer_org_v1_5_300_300_cosine              pvdm        128   \n",
       "doc2vec-gensim_original_articles_100001_300_300...         pvdm        128   \n",
       "doc2vec-gensim_original_articles_5_100_100_cosine          pvdm        128   \n",
       "doc2vec-gensim_original_articles_5_300_300_cosine          pvdm        128   \n",
       "pvdm_original_articles_10000_300_300_cosine                pvdm        128   \n",
       "pvdm_original_articles_1000_300_300_cosine                 pvdm        128   \n",
       "pvdm_original_articles_100_300_300_cosine                  pvdm        128   \n",
       "pvdm_original_articles_50000_300_300_cosine                pvdm        128   \n",
       "\n",
       "                                                   concat               data  \\\n",
       "doc2vec-gensim_aminer_org_v1_5_300_300_cosine        True      aminer_org_v1   \n",
       "doc2vec-gensim_original_articles_100001_300_300...   True  original_articles   \n",
       "doc2vec-gensim_original_articles_5_100_100_cosine    True  original_articles   \n",
       "doc2vec-gensim_original_articles_5_300_300_cosine    True  original_articles   \n",
       "pvdm_original_articles_10000_300_300_cosine          True  original_articles   \n",
       "pvdm_original_articles_1000_300_300_cosine           True  original_articles   \n",
       "pvdm_original_articles_100_300_300_cosine            True  original_articles   \n",
       "pvdm_original_articles_50000_300_300_cosine          True  original_articles   \n",
       "\n",
       "                                                   dist_measure document_size  \\\n",
       "doc2vec-gensim_aminer_org_v1_5_300_300_cosine            cosine        111000   \n",
       "doc2vec-gensim_original_articles_100001_300_300...       cosine          1031   \n",
       "doc2vec-gensim_original_articles_5_100_100_cosine        cosine          1031   \n",
       "doc2vec-gensim_original_articles_5_300_300_cosine        cosine          1031   \n",
       "pvdm_original_articles_10000_300_300_cosine              cosine          1031   \n",
       "pvdm_original_articles_1000_300_300_cosine               cosine          1031   \n",
       "pvdm_original_articles_100_300_300_cosine                cosine          1031   \n",
       "pvdm_original_articles_50000_300_300_cosine              cosine          1031   \n",
       "\n",
       "                                                   emb_size_d     ...      \\\n",
       "doc2vec-gensim_aminer_org_v1_5_300_300_cosine             300     ...       \n",
       "doc2vec-gensim_original_articles_100001_300_300...        300     ...       \n",
       "doc2vec-gensim_original_articles_5_100_100_cosine         100     ...       \n",
       "doc2vec-gensim_original_articles_5_300_300_cosine         300     ...       \n",
       "pvdm_original_articles_10000_300_300_cosine               300     ...       \n",
       "pvdm_original_articles_1000_300_300_cosine                300     ...       \n",
       "pvdm_original_articles_100_300_300_cosine                 300     ...       \n",
       "pvdm_original_articles_50000_300_300_cosine               300     ...       \n",
       "\n",
       "                                                   iterations learning_rate  \\\n",
       "doc2vec-gensim_aminer_org_v1_5_300_300_cosine               5             1   \n",
       "doc2vec-gensim_original_articles_100001_300_300...        NaN             1   \n",
       "doc2vec-gensim_original_articles_5_100_100_cosine           5             1   \n",
       "doc2vec-gensim_original_articles_5_300_300_cosine           5             1   \n",
       "pvdm_original_articles_10000_300_300_cosine               NaN             1   \n",
       "pvdm_original_articles_1000_300_300_cosine                NaN             1   \n",
       "pvdm_original_articles_100_300_300_cosine                 NaN             1   \n",
       "pvdm_original_articles_50000_300_300_cosine               NaN             1   \n",
       "\n",
       "                                                               loss_type  \\\n",
       "doc2vec-gensim_aminer_org_v1_5_300_300_cosine       sampled_softmax_loss   \n",
       "doc2vec-gensim_original_articles_100001_300_300...  sampled_softmax_loss   \n",
       "doc2vec-gensim_original_articles_5_100_100_cosine   sampled_softmax_loss   \n",
       "doc2vec-gensim_original_articles_5_300_300_cosine   sampled_softmax_loss   \n",
       "pvdm_original_articles_10000_300_300_cosine         sampled_softmax_loss   \n",
       "pvdm_original_articles_1000_300_300_cosine          sampled_softmax_loss   \n",
       "pvdm_original_articles_100_300_300_cosine           sampled_softmax_loss   \n",
       "pvdm_original_articles_50000_300_300_cosine         sampled_softmax_loss   \n",
       "\n",
       "                                                   n_neg_samples n_steps  \\\n",
       "doc2vec-gensim_aminer_org_v1_5_300_300_cosine                 64  555000   \n",
       "doc2vec-gensim_original_articles_100001_300_300...            64  100001   \n",
       "doc2vec-gensim_original_articles_5_100_100_cosine             64    5155   \n",
       "doc2vec-gensim_original_articles_5_300_300_cosine             64    5155   \n",
       "pvdm_original_articles_10000_300_300_cosine                   64   10000   \n",
       "pvdm_original_articles_1000_300_300_cosine                    64    1000   \n",
       "pvdm_original_articles_100_300_300_cosine                     64     100   \n",
       "pvdm_original_articles_50000_300_300_cosine                   64   50000   \n",
       "\n",
       "                                                    nsteps optimize  \\\n",
       "doc2vec-gensim_aminer_org_v1_5_300_300_cosine          NaN  Adagrad   \n",
       "doc2vec-gensim_original_articles_100001_300_300...  100001  Adagrad   \n",
       "doc2vec-gensim_original_articles_5_100_100_cosine      NaN  Adagrad   \n",
       "doc2vec-gensim_original_articles_5_300_300_cosine      NaN  Adagrad   \n",
       "pvdm_original_articles_10000_300_300_cosine          10000  Adagrad   \n",
       "pvdm_original_articles_1000_300_300_cosine            1000  Adagrad   \n",
       "pvdm_original_articles_100_300_300_cosine              100  Adagrad   \n",
       "pvdm_original_articles_50000_300_300_cosine          50000  Adagrad   \n",
       "\n",
       "                                                   prior_sample_size  \\\n",
       "doc2vec-gensim_aminer_org_v1_5_300_300_cosine                    NaN   \n",
       "doc2vec-gensim_original_articles_100001_300_300...               NaN   \n",
       "doc2vec-gensim_original_articles_5_100_100_cosine                NaN   \n",
       "doc2vec-gensim_original_articles_5_300_300_cosine                NaN   \n",
       "pvdm_original_articles_10000_300_300_cosine                       10   \n",
       "pvdm_original_articles_1000_300_300_cosine                        10   \n",
       "pvdm_original_articles_100_300_300_cosine                         10   \n",
       "pvdm_original_articles_50000_300_300_cosine                       10   \n",
       "\n",
       "                                                   vocabulary_size window_size  \n",
       "doc2vec-gensim_aminer_org_v1_5_300_300_cosine                50000           8  \n",
       "doc2vec-gensim_original_articles_100001_300_300...           50000           8  \n",
       "doc2vec-gensim_original_articles_5_100_100_cosine            50000           8  \n",
       "doc2vec-gensim_original_articles_5_300_300_cosine            50000           8  \n",
       "pvdm_original_articles_10000_300_300_cosine                  50000           8  \n",
       "pvdm_original_articles_1000_300_300_cosine                   50000           8  \n",
       "pvdm_original_articles_100_300_300_cosine                    50000           8  \n",
       "pvdm_original_articles_50000_300_300_cosine                  50000           8  \n",
       "\n",
       "[8 rows x 23 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "raw_data_folder = 'aminer_org_v1'\n",
    "rel_labels_fname = 'relevance_labels_' + raw_data_folder + '.p'\n",
    "with open(rel_labels_fname, 'rb') as rel_lab_file:\n",
    "    _, _, _, tokenized, _, sorted_bm25_indices = pickle.load(rel_lab_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1031\n",
      "Computing BM25...\n",
      "Done computing bm25, compute average IDF...\n",
      "Done computing average IDF.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import gensim\n",
    "output_fname='rel_labels.p'\n",
    "folder='original_articles'\n",
    "source_dict = {}  # maps article filename to source\n",
    "docs = []  # list with documents\n",
    "doc_names = []  # doc names with same index as docs\n",
    "\n",
    "data_path = os.path.join(os.getcwd(), 'raw_data.tmp', folder)\n",
    "for subdir, dirs, files in os.walk(data_path):\n",
    "    files = [fi for fi in files if fi.endswith(\".txt\")]\n",
    "    for file in files:\n",
    "        path = os.path.join(subdir, file)\n",
    "        folder_name = subdir.split(os.path.sep)[-1]\n",
    "        fname = file[:-4]\n",
    "        source_dict[fname] = subdir.split(os.path.sep)[-1]\n",
    "        with open(path, 'r', encoding='utf8') as f:\n",
    "            docs.append(f.read())\n",
    "        doc_names.append(fname)\n",
    "\n",
    "tokenized = []\n",
    "for doc in docs:\n",
    "    tokens = [word for sent in nltk.sent_tokenize(doc) for word in nltk.word_tokenize(sent)]\n",
    "    tokenized.append(tokens)\n",
    "\n",
    "print(len(docs))\n",
    "print(\"Computing BM25...\")\n",
    "bm25 = gensim.summarization.bm25.BM25(tokenized)\n",
    "print(\"Done computing bm25, compute average IDF...\")\n",
    "average_idf = sum(map(lambda k: float(bm25.idf[k]), bm25.idf.keys())) / len(bm25.idf.keys())\n",
    "print(\"Done computing average IDF.\")\n",
    "bm25_scores = []\n",
    "sorted_bm25_indices = []\n",
    "len_tokenized = len(tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article 517 Definition of eligible capital By 31 December 2014 the Commission shall review and report on the appropriateness of the definition of eligible capital being applied for the purposes of Title III of Part Two and Part Four and shall submit that report to the European Parliament and the Council , and , if appropriate , a legislative proposal .\n",
      "867\n"
     ]
    }
   ],
   "source": [
    "doc = tokenized[500]\n",
    "print(' '.join(doc))\n",
    "temp_bm25_scores = bm25.get_scores(doc, average_idf)\n",
    "temp_bm25_scores = temp_bm25_scores\n",
    "sorted_indices = sorted(range(len(temp_bm25_scores)), key=lambda x: temp_bm25_scores[x], reverse=True)\n",
    "# print(sorted_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim import corpora\n",
    "import math\n",
    "\n",
    "class BM25 :\n",
    "    def __init__(self, fn_docs) :\n",
    "        self.dictionary = corpora.Dictionary()\n",
    "        self.doc_names = []\n",
    "        self.source_dict = {}\n",
    "        self.DF = {}\n",
    "        self.DocTF = []\n",
    "        self.DocIDF = {}\n",
    "        self.N = 0\n",
    "        self.DocAvgLen = 0\n",
    "        self.fn_docs = fn_docs\n",
    "        self.DocLen = []\n",
    "        self.buildDictionary()\n",
    "        self.TFIDF_Generator()\n",
    "\n",
    "    def buildDictionary(self) :\n",
    "        raw_data = []\n",
    "#         for line in file(self.fn_docs) :\n",
    "#             raw_data.append(line.strip().split(self.delimiter))\n",
    "        data_path = os.path.join(os.getcwd(), 'raw_data.tmp', self.fn_docs)\n",
    "        for subdir, dirs, files in os.walk(data_path):\n",
    "            files = [fi for fi in files if fi.endswith(\".txt\")]\n",
    "            for file in files:\n",
    "                path = os.path.join(subdir, file)\n",
    "                folder_name = subdir.split(os.path.sep)[-1]\n",
    "                fname = file[:-4]\n",
    "                self.source_dict[fname] = subdir.split(os.path.sep)[-1]\n",
    "                with open(path, 'r', encoding='utf8') as f:\n",
    "                    raw_data.append([word for sent in nltk.sent_tokenize(f.read()) for word in nltk.word_tokenize(sent)])\n",
    "                self.doc_names.append(fname)\n",
    "        self.dictionary.add_documents(raw_data)\n",
    "\n",
    "    def TFIDF_Generator(self, base=math.e) :\n",
    "        docTotalLen = 0\n",
    "        data_path = os.path.join(os.getcwd(), 'raw_data.tmp', self.fn_docs)\n",
    "        for subdir, dirs, files in os.walk(data_path):\n",
    "            files = [fi for fi in files if fi.endswith(\".txt\")]\n",
    "            for file in files:\n",
    "                path = os.path.join(subdir, file)\n",
    "                with open(path, 'r', encoding='utf8') as f:\n",
    "                    doc = [word for sent in nltk.sent_tokenize(f.read()) for word in nltk.word_tokenize(sent)]\n",
    "                docTotalLen += len(doc)\n",
    "                self.DocLen.append(len(doc))\n",
    "                bow = dict([(term, freq*1.0/len(doc)) for term, freq in self.dictionary.doc2bow(doc)])\n",
    "                for term, tf in bow.items() :\n",
    "                    if term not in self.DF :\n",
    "                        self.DF[term] = 0\n",
    "                    self.DF[term] += 1\n",
    "                self.DocTF.append(bow)\n",
    "                self.N = self.N + 1\n",
    "        for term in self.DF:\n",
    "            self.DocIDF[term] = math.log((self.N - self.DF[term] +0.5) / (self.DF[term] + 0.5), base)\n",
    "        self.DocAvgLen = docTotalLen / self.N\n",
    "\n",
    "    def BM25Score(self, Query=[], k1=1.5, b=0.75) :\n",
    "        query_bow = self.dictionary.doc2bow(Query)\n",
    "        scores = []\n",
    "        for idx, doc in enumerate(self.DocTF) :\n",
    "            commonTerms = set(dict(query_bow).keys()) & set(doc.keys())\n",
    "            tmp_score = []\n",
    "            doc_terms_len = self.DocLen[idx]\n",
    "            for term in commonTerms :\n",
    "                upper = (doc[term] * (k1+1))\n",
    "                below = ((doc[term]) + k1*(1 - b + b*doc_terms_len/self.DocAvgLen))\n",
    "                tmp_score.append(self.DocIDF[term] * upper / below)\n",
    "            scores.append(sum(tmp_score))\n",
    "        return scores\n",
    "\n",
    "    def TFIDF(self) :\n",
    "        tfidf = []\n",
    "        for doc in self.DocTF :\n",
    "            doc_tfidf  = [(term, tf*self.DocIDF[term]) for term, tf in doc.items()]\n",
    "            doc_tfidf.sort()\n",
    "            tfidf.append(doc_tfidf)\n",
    "        return tfidf\n",
    "\n",
    "    def Items(self) :\n",
    "        # Return a list [(term_idx, term_desc),]\n",
    "        items = self.dictionary.items()\n",
    "        items.sort()\n",
    "        return items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import gensim\n",
    "output_fname='rel_labels.p'\n",
    "folder='aminer_org_v1'\n",
    "source_dict = {}  # maps article filename to source\n",
    "docs = []  # list with documents\n",
    "doc_names = []  # doc names with same index as docs\n",
    "\n",
    "data_path = os.path.join(os.getcwd(), 'raw_data.tmp', folder)\n",
    "for subdir, dirs, files in os.walk(data_path):\n",
    "    files = [fi for fi in files if fi.endswith(\".txt\")]\n",
    "    for file in files:\n",
    "        path = os.path.join(subdir, file)\n",
    "        folder_name = subdir.split(os.path.sep)[-1]\n",
    "        fname = file[:-4]\n",
    "        source_dict[fname] = subdir.split(os.path.sep)[-1]\n",
    "        with open(path, 'r', encoding='utf8') as f:\n",
    "            docs.append(f.read())\n",
    "        doc_names.append(fname)\n",
    "\n",
    "tokenized = []\n",
    "for doc in docs:\n",
    "    tokens = [word for sent in nltk.sent_tokenize(doc) for word in nltk.word_tokenize(sent)]\n",
    "    tokenized.append(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_docs = 'aminer_org_v1'\n",
    "bm25 = BM25(fn_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91283\n",
      "[91283, 6339, 72175, 33383, 57814, 109712, 19367, 94624, 35338, 22166]\n",
      "\n",
      "Original text:\n",
      "\n",
      "Dynamically managing the communication-parallelism trade-off in future clustered processors Clustered microarchitectures are an attractive alternative to large monolithic superscalar designs due to their potential for higher clock rates in the face of increasingly wire-delay-constrained process technologies . As increasing transistor counts allow an increase in the number of clusters , thereby allowing more aggressive use of instruction-level parallelism ( ILP ) , the inter-cluster communication increases as data values get spread across a wider area . As a result of the emergence of this trade-off between communication and parallelism , a subset of the total on-chip clusters is optimal for performance . To match the hardware to the application 's needs , we use a robust algorithm to dynamically tune the clustered architecture . The algorithm , which is based on program metrics gathered at periodic intervals , achieves an 11 % performance improvement on average over the best statically defined architecture . We also show that the use of additional hardware and reconfiguration at basic block boundaries can achieve average improvements of 15 % . Our results demonstrate that reconfiguration provides an effective solution to the communication and parallelism trade-off inherent in the communication-bound processors of the future .\n",
      "\n",
      "Top 5:\n",
      "\n",
      "Dynamically managing the communication-parallelism trade-off in future clustered processors Clustered microarchitectures are an attractive alternative to large monolithic superscalar designs due to their potential for higher clock rates in the face of increasingly wire-delay-constrained process technologies . As increasing transistor counts allow an increase in the number of clusters , thereby allowing more aggressive use of instruction-level parallelism ( ILP ) , the inter-cluster communication increases as data values get spread across a wider area . As a result of the emergence of this trade-off between communication and parallelism , a subset of the total on-chip clusters is optimal for performance . To match the hardware to the application 's needs , we use a robust algorithm to dynamically tune the clustered architecture . The algorithm , which is based on program metrics gathered at periodic intervals , achieves an 11 % performance improvement on average over the best statically defined architecture . We also show that the use of additional hardware and reconfiguration at basic block boundaries can achieve average improvements of 15 % . Our results demonstrate that reconfiguration provides an effective solution to the communication and parallelism trade-off inherent in the communication-bound processors of the future . \n",
      "--------------------\n",
      "\n",
      "Emergent process design No abstract available \n",
      "--------------------\n",
      "\n",
      "Guest Editors ' Introduction : High-Performance Reconfigurable Computing High-performance reconfigurable computers have the potential to exploit coarse-grained functional parallelism as well as fine-grained instruction-level parallelism through direct hardware execution on FPGAs . \n",
      "--------------------\n",
      "\n",
      "Agile software reuse recommender No abstract available \n",
      "--------------------\n",
      "\n",
      "Self-assessment procedure XVII A self-assessment procedure dealing with ACM \n",
      "--------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def inspect(index):\n",
    "    print(index)\n",
    "    Query = tokenized[index]\n",
    "    scores = bm25.BM25Score(Query)\n",
    "    sorted_indices = sorted(range(len(scores)), key=lambda x: scores[x], reverse=True)\n",
    "    print(sorted_indices[:10])\n",
    "    print('\\nOriginal text:\\n')\n",
    "    print(' '.join(tokenized[index][:300]))\n",
    "    print('\\nTop 5:\\n')\n",
    "    for i in range(5):\n",
    "        print(' '.join(tokenized[sorted_indices[i]]),'\\n--------------------\\n')\n",
    "\n",
    "index = np.random.randint(len(tokenized))\n",
    "inspect(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/alexandervansomeren/Documents/Studie/Msc_AI/Thesis/regulatory tracker/doc2vec_pipeline/raw_data.tmp/original_articles\n"
     ]
    }
   ],
   "source": [
    "fn_docs = 'original_articles'\n",
    "\n",
    "\n",
    "raw_data = []\n",
    "data_path = os.path.join(os.getcwd(), 'raw_data.tmp', fn_docs)\n",
    "print(data_path)\n",
    "doc_names=[]\n",
    "dictionary=corpora.Dictionary()\n",
    "for subdir, dirs, files in os.walk(data_path):\n",
    "    files = [fi for fi in files if fi.endswith(\".txt\")]\n",
    "    for file in files:\n",
    "        path = os.path.join(subdir, file)\n",
    "        folder_name = subdir.split(os.path.sep)[-1]\n",
    "        fname = file[:-4]\n",
    "        source_dict[fname] = subdir.split(os.path.sep)[-1]\n",
    "        with open(path, 'r', encoding='utf8') as f:\n",
    "            raw_data.append([word for sent in nltk.sent_tokenize(f.read()) for word in nltk.word_tokenize(sent)])\n",
    "        doc_names.append(fname)\n",
    "dictionary.add_documents(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "doc2bow() missing 1 required positional argument: 'document'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-77-5f98ec8bc765>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdictionary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdoc2bow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: doc2bow() missing 1 required positional argument: 'document'"
     ]
    }
   ],
   "source": [
    "dictionary.doc2bow()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:regulatory_tracker]",
   "language": "python",
   "name": "conda-env-regulatory_tracker-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "nbpresent": {
   "slides": {
    "7bdfc0fc-9cb9-4774-aaa5-ec1059c174ed": {
     "id": "7bdfc0fc-9cb9-4774-aaa5-ec1059c174ed",
     "prev": "8b4c6ddd-df51-456d-b79a-2ca76c61163f",
     "regions": {
      "b4df9567-5fa8-45a1-b5fc-1330bfafb954": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "4f833753-0a8c-48d8-b5f1-6b8660996bb6",
        "part": "whole"
       },
       "id": "b4df9567-5fa8-45a1-b5fc-1330bfafb954"
      }
     }
    },
    "8b4c6ddd-df51-456d-b79a-2ca76c61163f": {
     "id": "8b4c6ddd-df51-456d-b79a-2ca76c61163f",
     "prev": null,
     "regions": {}
    }
   },
   "themes": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
